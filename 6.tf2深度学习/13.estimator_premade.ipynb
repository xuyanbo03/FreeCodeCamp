{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用预定义的estimator处理titanic问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "sklearn 0.22.1\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# 导入\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "def solve_cudnn_error():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "solve_cudnn_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据，构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "train_file = 'data/titanic/train.csv'\n",
    "eval_file = 'data/titanic/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 将survived字段取出，赋给label\n",
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 将数据分成两类：离散和连续\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    # 获取离散值所有可能值\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    # 对离散值封装，做onehot编码，再加入feature_columns中\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "    \n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从pandas dataframe中构建dataset\n",
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def make_input_fn(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    def input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(10000)\n",
    "        dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "        return dataset\n",
    "    return input_fn\n",
    "\n",
    "train_input_fn = make_input_fn(train_df, y_train, epochs=100)\n",
    "eval_input_fn = make_input_fn(eval_df, y_eval, epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用预定义的estimator\n",
    "\n",
    "### BaseLine Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # 定义文件夹，保存输出的模型\n",
    "# output_dir = 'baseline_model'\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.mkdir(output_dir)\n",
    "# else:\n",
    "#     shutil.rmtree(output_dir)\n",
    "#     os.mkdir(output_dir)\n",
    "    \n",
    "# baseline_estimator = tf.estimator.BaselineClassifier(\n",
    "#     model_dir=output_dir, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_estimator.train(\n",
    "#     input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_estimator.evaluate(\n",
    "#     input_fn=lambda : make_dataset(\n",
    "#         eval_df, y_eval, epochs=1, shuffle=False, batch_size=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'linear_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000017EDF3D5E80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "# 定义文件夹，保存输出的模型\n",
    "linear_output_dir = 'linear_model'\n",
    "if not os.path.exists(linear_output_dir):\n",
    "    os.mkdir(linear_output_dir)\n",
    "else:\n",
    "    shutil.rmtree(linear_output_dir)\n",
    "    os.mkdir(linear_output_dir)\n",
    "    \n",
    "linear_estimator = tf.estimator.LinearClassifier(\n",
    "    model_dir=linear_output_dir,\n",
    "#     n_classes=2, \n",
    "    feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into linear_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6931472, step = 0\n",
      "INFO:tensorflow:global_step/sec: 146.089\n",
      "INFO:tensorflow:loss = 0.42974675, step = 100 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.207\n",
      "INFO:tensorflow:loss = 0.62175107, step = 200 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.567\n",
      "INFO:tensorflow:loss = 0.51646996, step = 300 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.669\n",
      "INFO:tensorflow:loss = 0.44153577, step = 400 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.63\n",
      "INFO:tensorflow:loss = 0.4308874, step = 500 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.667\n",
      "INFO:tensorflow:loss = 0.415779, step = 600 (0.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.777\n",
      "INFO:tensorflow:loss = 0.39096814, step = 700 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.322\n",
      "INFO:tensorflow:loss = 0.2098391, step = 800 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.145\n",
      "INFO:tensorflow:loss = 0.3097522, step = 900 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.346\n",
      "INFO:tensorflow:loss = 0.42066818, step = 1000 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.607\n",
      "INFO:tensorflow:loss = 0.1932587, step = 1100 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.791\n",
      "INFO:tensorflow:loss = 0.4141824, step = 1200 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.024\n",
      "INFO:tensorflow:loss = 0.44350308, step = 1300 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.467\n",
      "INFO:tensorflow:loss = 0.3671273, step = 1400 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.515\n",
      "INFO:tensorflow:loss = 0.390425, step = 1500 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.63\n",
      "INFO:tensorflow:loss = 0.4672044, step = 1600 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.215\n",
      "INFO:tensorflow:loss = 0.3382621, step = 1700 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.08\n",
      "INFO:tensorflow:loss = 0.33428866, step = 1800 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.911\n",
      "INFO:tensorflow:loss = 0.30520147, step = 1900 (0.540 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into linear_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.39376664.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifierV2 at 0x17ec793ba58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.train(\n",
    "    input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-06T22:36:34Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from linear_model\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-06-22:36:35\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.78409094, accuracy_baseline = 0.625, auc = 0.83914894, auc_precision_recall = 0.7815013, average_loss = 0.46964055, global_step = 1960, label/mean = 0.375, loss = 0.45359072, precision = 0.71428573, prediction/mean = 0.3719563, recall = 0.7070707\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: linear_model\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78409094,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.83914894,\n",
       " 'auc_precision_recall': 0.7815013,\n",
       " 'average_loss': 0.46964055,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.45359072,\n",
       " 'precision': 0.71428573,\n",
       " 'prediction/mean': 0.3719563,\n",
       " 'recall': 0.7070707,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_estimator.evaluate(\n",
    "    input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'dnn_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002340818EDA0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "# 定义文件夹，保存输出的模型\n",
    "dnn_output_dir = 'dnn_model'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "else:\n",
    "    shutil.rmtree(dnn_output_dir)\n",
    "    os.mkdir(dnn_output_dir)\n",
    "    \n",
    "dnn_estimator = tf.estimator.DNNClassifier(\n",
    "    model_dir=dnn_output_dir,\n",
    "#     n_classes=2,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[128,128],\n",
    "    activation_fn=tf.nn.relu,\n",
    "    optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py:206: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into dnn_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.5659068, step = 0\n",
      "INFO:tensorflow:global_step/sec: 149.219\n",
      "INFO:tensorflow:loss = 0.6483451, step = 100 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.666\n",
      "INFO:tensorflow:loss = 0.54390943, step = 200 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.249\n",
      "INFO:tensorflow:loss = 0.4500445, step = 300 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.329\n",
      "INFO:tensorflow:loss = 0.442823, step = 400 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.127\n",
      "INFO:tensorflow:loss = 0.51294166, step = 500 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.612\n",
      "INFO:tensorflow:loss = 0.49308866, step = 600 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.843\n",
      "INFO:tensorflow:loss = 0.46976888, step = 700 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.698\n",
      "INFO:tensorflow:loss = 0.28390783, step = 800 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.706\n",
      "INFO:tensorflow:loss = 0.35449278, step = 900 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.606\n",
      "INFO:tensorflow:loss = 0.49086595, step = 1000 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.652\n",
      "INFO:tensorflow:loss = 0.29173502, step = 1100 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.001\n",
      "INFO:tensorflow:loss = 0.5909201, step = 1200 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.398\n",
      "INFO:tensorflow:loss = 0.409008, step = 1300 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.234\n",
      "INFO:tensorflow:loss = 0.35488045, step = 1400 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.691\n",
      "INFO:tensorflow:loss = 0.33016568, step = 1500 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.71\n",
      "INFO:tensorflow:loss = 0.38078, step = 1600 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.785\n",
      "INFO:tensorflow:loss = 0.23298112, step = 1700 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.218\n",
      "INFO:tensorflow:loss = 0.27804404, step = 1800 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.663\n",
      "INFO:tensorflow:loss = 0.454516, step = 1900 (0.530 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into dnn_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1548893.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x2340817ba58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.train(\n",
    "    input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-02-06T22:42:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from dnn_model\\model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-02-06-22:42:33\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.780303, accuracy_baseline = 0.625, auc = 0.83663905, auc_precision_recall = 0.79695463, average_loss = 0.5478012, global_step = 1960, label/mean = 0.375, loss = 0.52315557, precision = 0.664, prediction/mean = 0.45481092, recall = 0.83838385\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: dnn_model\\model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.780303,\n",
       " 'accuracy_baseline': 0.625,\n",
       " 'auc': 0.83663905,\n",
       " 'auc_precision_recall': 0.79695463,\n",
       " 'average_loss': 0.5478012,\n",
       " 'label/mean': 0.375,\n",
       " 'loss': 0.52315557,\n",
       " 'precision': 0.664,\n",
       " 'prediction/mean': 0.45481092,\n",
       " 'recall': 0.83838385,\n",
       " 'global_step': 1960}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.evaluate(\n",
    "    input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉特征\n",
    "cross feature：对两个离散特征做笛卡尔积\n",
    "\n",
    "Eg：\n",
    "\n",
    "age:[1,2,3,4,5], gender:[male, female]\n",
    "\n",
    "age_x_gender:[(1,male),...,(5,male), (1,male),...,(5,female)]\n",
    "\n",
    "100000:100 -> hash(100000 values) % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.feature_column.crossed_column 定义交叉特征\n",
    "feature_columns.append(tf.feature_column.indicator_column(\n",
    "    tf.feature_column.crossed_column(['age', 'sex'], hash_bucket_size=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'dnn_model_new_feature', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001DD1C39EB70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "# 定义文件夹，保存输出的模型\n",
    "dnn_output_dir = 'dnn_model_new_feature'\n",
    "if not os.path.exists(dnn_output_dir):\n",
    "    os.mkdir(dnn_output_dir)\n",
    "else:\n",
    "    shutil.rmtree(dnn_output_dir)\n",
    "    os.mkdir(dnn_output_dir)\n",
    "    \n",
    "dnn_estimator_new = tf.estimator.DNNClassifier(\n",
    "    model_dir=dnn_output_dir,\n",
    "#     n_classes=2,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[128,128],\n",
    "    activation_fn=tf.nn.relu,\n",
    "    optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: CrossedColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From f:\\condaenv\\tf2_py36\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\head\\binary_class_head.py:206: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    }
   ],
   "source": [
    "dnn_estimator_new.train(\n",
    "    input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_estimator_new.evaluate(\n",
    "    input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
