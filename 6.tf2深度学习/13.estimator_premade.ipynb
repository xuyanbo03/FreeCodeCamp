{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用预定义的estimator处理titanic问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "sklearn 0.22.1\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# 导入\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据，构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "train_file = 'data/titanic/train.csv'\n",
    "eval_file = 'data/titanic/eval.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 将survived字段取出，赋给label\n",
    "y_train = train_df.pop('survived')\n",
    "y_eval = eval_df.pop('survived')\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 将数据分成两类：离散和连续\n",
    "categorical_columns = ['sex', 'n_siblings_spouses', 'parch', 'class',\n",
    "                       'deck', 'embark_town', 'alone']\n",
    "numeric_columns = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    # 获取离散值所有可能值\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    # 对离散值封装，做onehot编码，再加入feature_columns中\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.indicator_column(\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                categorical_column, vocab)))\n",
    "    \n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从pandas dataframe中构建dataset\n",
    "def make_dataset(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def make_input_fn(data_df, label_df, epochs = 10, shuffle = True, batch_size = 32):\n",
    "    def input_fn():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(10000)\n",
    "        dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "        return dataset\n",
    "    return input_fn\n",
    "\n",
    "train_input_fn = make_input_fn(train_df, y_train, epochs=100)\n",
    "eval_input_fn = make_input_fn(eval_df, y_eval, epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用预定义的estimator\n",
    "\n",
    "### BaseLine Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # 定义文件夹，保存输出的模型\n",
    "# output_dir = 'baseline_model'\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.mkdir(output_dir)\n",
    "# else:\n",
    "#     shutil.rmtree(output_dir)\n",
    "#     os.mkdir(output_dir)\n",
    "    \n",
    "# baseline_estimator = tf.estimator.BaselineClassifier(\n",
    "#     model_dir=output_dir, n_classes=2)\n",
    "# baseline_estimator.train(\n",
    "#     input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_estimator.evaluate(\n",
    "#     input_fn=lambda : make_dataset(\n",
    "#         eval_df, y_eval, epochs=1, shuffle=False, batch_size=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # 定义文件夹，保存输出的模型\n",
    "# linear_output_dir = 'linear_model'\n",
    "# if not os.path.exists(linear_output_dir):\n",
    "#     os.mkdir(linear_output_dir)\n",
    "# else:\n",
    "#     shutil.rmtree(linear_output_dir)\n",
    "#     os.mkdir(linear_output_dir)\n",
    "    \n",
    "# linear_estimator = tf.estimator.LinearClassifier(\n",
    "#     model_dir=linear_output_dir, n_classes=2, feature_columns=feature_columns)\n",
    "# linear_estimator.train(\n",
    "#     input_fn=lambda : make_dataset(train_df, y_train, epochs=100))\n",
    "\n",
    "# linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "# linear_est.train(train_input_fn)\n",
    "# result = linear_est.evaluate(eval_input_fn)\n",
    "\n",
    "# clear_output()\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_estimator.evaluate(\n",
    "#     input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # 定义文件夹，保存输出的模型\n",
    "# dnn_output_dir = 'dnn_model'\n",
    "# if not os.path.exists(dnn_output_dir):\n",
    "#     os.mkdir(dnn_output_dir)\n",
    "# else:\n",
    "#     shutil.rmtree(dnn_output_dir)\n",
    "#     os.mkdir(dnn_output_dir)\n",
    "    \n",
    "# dnn_estimator = tf.estimator.DNNClassifier(\n",
    "#     model_dir=dnn_output_dir,\n",
    "#     n_classes=2,\n",
    "#     feature_columns=feature_columns,\n",
    "#     hidden_units=[128,128],\n",
    "#     activation_fn=tf.nn.relu,\n",
    "#     optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn_estimator.train(\n",
    "#     input_fn=lambda : make_dataset(train_df, y_train, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn_estimator.evaluate(\n",
    "#     input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉特征\n",
    "cross feature：对两个离散特征做笛卡尔积\n",
    "\n",
    "Eg：\n",
    "\n",
    "age:[1,2,3,4,5], gender:[male, female]\n",
    "\n",
    "age_x_gender:[(1,male),...,(5,male), (1,male),...,(5,female)]\n",
    "\n",
    "100000:100 -> hash(100000 values) % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.feature_column.crossed_column 定义交叉特征\n",
    "feature_columns.append(tf.feature_column.indicator_column(\n",
    "    tf.feature_column.crossed_column(['age', 'sex'], hash_bucket_size=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# # 定义文件夹，保存输出的模型\n",
    "# dnn_output_dir = 'dnn_model_new_feature'\n",
    "# if not os.path.exists(dnn_output_dir):\n",
    "#     os.mkdir(dnn_output_dir)\n",
    "# else:\n",
    "#     shutil.rmtree(dnn_output_dir)\n",
    "#     os.mkdir(dnn_output_dir)\n",
    "    \n",
    "# dnn_estimator = tf.estimator.DNNClassifier(\n",
    "#     model_dir=dnn_output_dir,\n",
    "#     n_classes=2,\n",
    "#     feature_columns=feature_columns,\n",
    "#     hidden_units=[128,128],\n",
    "#     activation_fn=tf.nn.relu,\n",
    "#     optimizer='Adam')\n",
    "\n",
    "# dnn_estimator.train(\n",
    "#     input_fn=lambda : make_dataset(train_df, y_train, epochs=100))\n",
    "\n",
    "# dnn_estimator.evaluate(\n",
    "#     input_fn=lambda : make_dataset(eval_df, y_eval, epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
