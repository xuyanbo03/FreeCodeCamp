{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## \u4e0b\u8f7d\u6570\u636e\u96c6"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import moxing as mox\n# path \u6700\u597d\u6362\u6210\u81ea\u5df1\u7684\nmox.file.copy_parallel('s3://ai-awe-n4/aifood','./aifood/')\nprint(\"done\")", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "INFO:root:Listing OBS: 1000\nINFO:root:Listing OBS: 2000\nINFO:root:Listing OBS: 3000\nINFO:root:Listing OBS: 4000\nINFO:root:Listing OBS: 5000\nINFO:root:Listing OBS: 6000\nINFO:root:Listing OBS: 7000\nINFO:root:Listing OBS: 8000\nINFO:root:Listing OBS: 9000\nINFO:root:Listing OBS: 10000\nINFO:root:Listing OBS: 11000\nINFO:root:pid: None.\t1000/11501\nINFO:root:pid: None.\t2000/11501\nINFO:root:pid: None.\t3000/11501\nINFO:root:pid: None.\t4000/11501\nINFO:root:pid: None.\t5000/11501\nINFO:root:pid: None.\t6000/11501\nINFO:root:pid: None.\t7000/11501\nINFO:root:pid: None.\t8000/11501\nINFO:root:pid: None.\t9000/11501\nINFO:root:pid: None.\t10000/11501\nINFO:root:pid: None.\t11000/11501\n", "name": "stderr"}, {"output_type": "stream", "text": "done\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## \u5bfc\u5305\u548c\u6a21\u578b"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from __future__ import print_function, division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport time\nimport os\nimport random\nimport numpy as np", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# os.listdir('works')\n# \u8fd9\u91cc\u6211\u76f4\u63a5\u628a\u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u8f7d\u5230\u4e86obs\nmodel_names = os.listdir('./')\nprint(model_names)", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "['aifood', 'resnet50-19c8e357.pth']\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## \u52a0\u8f7d\u6570\u636e\u96c6\uff0c\u5e76\u5c06\u5176\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u624b\u52a8\u5199\u4e00\u4e2a\u7c7b\u6765\u8bfb\u53d6\u6570\u636e\nfrom torchvision.datasets import ImageFolder\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nsize = 224\n# \u4f7f\u7528image net\u7684mean std \u7b80\u5355\u7684\u6570\u636e\u589e\u5f3a\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ntrain_transformer_ImageNet = transforms.Compose([\n    transforms.Resize((size,size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n    transforms.ToTensor(),\n    normalize\n])\n \nval_transformer_ImageNet = transforms.Compose([\n    transforms.Resize((size,size)),\n    transforms.ToTensor(),\n    normalize\n])\n\n# \u76ee\u5f55\u6587\u4ef6\ndata_dir = './aifood/images'\n# \u4e3a\u4e86\u5212\u5206\u6570\u636e\u96c6\uff0c\u548c\u81ea\u5b9a\u4e49transform \u6240\u4ee5\u53c2\u8003\u5982\u4e0b\u94fe\u63a5\u5199\u4e86\u4e00\u4e2a\u8fd9\u4e2a\n# refer https://blog.csdn.net/ncc1995/article/details/91125964\nclass MyDataset(Dataset):\n    def __init__(self, filenames, labels, transform):\n        self.filenames = filenames\n        self.labels = labels\n        self.transform = transform\n \n    def __len__(self):\n        return len(self.filenames)\n \n    def __getitem__(self, idx):\n        image = Image.open(self.filenames[idx]).convert('RGB')\n        image = self.transform(image)\n        return image, self.labels[idx]\n\n    \ndef split_Train_Val_Data(data_dir, ratio, bs=64):\n    global train_len\n    global val_len\n    \"\"\" the sum of ratio must equal to 1\"\"\"\n    dataset = ImageFolder(data_dir)     # data_dir\u7cbe\u786e\u5230\u5206\u7c7b\u76ee\u5f55\u7684\u4e0a\u4e00\u7ea7\n    character = [[] for i in range(len(dataset.classes))]\n    print(dataset.class_to_idx)\n    for x, y in dataset.samples:  # \u5c06\u6570\u636e\u6309\u7c7b\u6807\u5b58\u653e\n        character[y].append(x)\n#     print(dataset.samples)\n    train_inputs, val_inputs, test_inputs = [], [], []\n    train_labels, val_labels, test_labels = [], [], []\n    for i, data in enumerate(character):   # data\u4e3a\u4e00\u7c7b\u56fe\u7247\n        num_sample_train = int(len(data) * ratio[0])\n        #print(num_sample_train)\n        num_sample_val = int(len(data) * ratio[1])\n        num_val_index = num_sample_train + num_sample_val\n        # \u8fd9\u91cc\u6253\u4e71\u4e00\u4e0b\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0d\u6253\u4e71\u4e5f\u6ca1\u4e8b\n        random.seed(7)\n        random.shuffle(data)\n        \n        for x in data[:num_sample_train]:\n            train_inputs.append(str(x))\n            train_labels.append(i)\n        for x in data[num_sample_train:num_val_index]:\n            val_inputs.append(str(x))\n            val_labels.append(i)\n    \n    train_len = len(train_inputs)\n    val_len = len(val_inputs)\n    print(\"train_length:%d,val length:%d\" %(train_len,val_len))\n    \n    train_dst = MyDataset(train_inputs, train_labels, train_transformer_ImageNet)\n    valid_dst = MyDataset(val_inputs, val_labels, val_transformer_ImageNet)\n    train_dataloader = DataLoader(train_dst,\n                                  batch_size=bs, shuffle=True)\n    val_dataloader = DataLoader(valid_dst,\n                                  batch_size=bs, shuffle=False)\n \n    return train_dataloader, val_dataloader\n\n# \u5b9a\u4e49pytorch\u7684dataloader\uff0c\u6570\u636e\u5212\u52060.9 \u53ef\u4ee5\u63d0\u5347\u4e00\u4e2a\u70b9\u5de6\u53f3\ndata_loader = split_Train_Val_Data(data_dir,(0.9,0.1))", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "{'\u4e09\u660e\u6cbb': 0, '\u51b0\u6fc0\u51cc': 1, '\u571f\u8c46\u6ce5': 2, '\u5c0f\u7c73\u7ca5': 3, '\u677e\u9f20\u9c7c': 4, '\u70e4\u51b7\u9762': 5, '\u7389\u7c73\u997c': 6, '\u751c\u751c\u5708': 7, '\u8292\u679c\u73ed\u621f': 8, '\u9e21\u86cb\u5e03\u4e01': 9}\ntrain_length:4500,val length:500\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u4e3a\u4e86\u4fdd\u8bc1\u540e\u9762\u548c\u5b98\u65b9\u7684baseline\u4e00\u81f4\uff0c\u6240\u4ee5\u53ef\u4ee5\u8fd9\u4e48\u5199\ndataloders = {x:  data_loader[i] for i,x in enumerate(['train', 'val']) }\ndataset_sizes = {'train':train_len, 'val':val_len}\nprint(dataset_sizes)\n# use gpu or not\nuse_gpu = torch.cuda.is_available()", "execution_count": 13, "outputs": [{"output_type": "stream", "text": "{'train': 4500, 'val': 500}\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u8fd9\u91cc\u8ba1\u7b97\u4e86\u4e00\u4e0b\u6240\u6709\u7167\u7247\u7684\u5747\u503c\uff0c\u65b9\u5dee\uff0c\u53ef\u4ee5\u914c\u60c5\u66ff\u6362imageNet \u7684\n# mean std = [0.6736, 0.5654, 0.4031],[0.1994, 0.2248, 0.2528]", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## \u8bad\u7ec3\u7f51\u7edc"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def train_model(model, lossfunc, optimizer, scheduler, num_epochs=10):\n    start_time = time.time()\n\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n    train_acc = []\n    valid_acc = []\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n#                 \n                model.train(True)  # Set model to training mode\n            else:\n                \n                model.train(False)  # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0.0\n\n            # Iterate over data.\n            for data in dataloders[phase]:\n                # get the inputs\n                inputs, labels = data\n                \n\n                # wrap them in Variable\n                if use_gpu:\n                    inputs = Variable(inputs.cuda())\n                    labels = Variable(labels.cuda())\n                else:\n                    inputs, labels = Variable(inputs), Variable(labels)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = lossfunc(outputs, labels)\n\n                # backward + optimize only if in training phase\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                # statistics\n                running_loss += loss.data\n                running_corrects += torch.sum(preds == labels.data).to(torch.float32)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            if phase == 'val':\n                valid_acc.append(epoch_acc)\n            else:\n                train_acc.append(epoch_acc)\n            \n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n        # \u8fd9\u91cc\u4f7f\u7528\u4e86\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\n        scheduler.step(valid_acc[-1])\n    elapsed_time = time.time() - start_time\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        elapsed_time // 60, elapsed_time % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n  \n    return model,train_acc,valid_acc", "execution_count": 15, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u4e4b\u524d\u624b\u5199\u7684\u6807\u7b7e\u5e73\u6ed1\u53ef\u4ee5\u76f4\u63a5\u7528\uff0c\u4e5f\u53ef\u4ee5\u4e0d\u7528\u3002\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n\n# export label smoothing\nfrom torch.autograd import Variable\n\ndef reduce_loss(loss, reduction='mean'):\n    return loss.mean() if reduction == 'mean' else loss.sum() if reduction == 'sum' else loss\n\ndef lin_comb(a, b, epsilon):\n    return epsilon * a + b * (1 - epsilon)\n\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, epsilon: float = 0.1, reduction='mean'):\n        super().__init__()\n        self.epsilon, self.reduction = epsilon, reduction\n\n    def forward(self, output, target):\n        c = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n        return lin_comb(loss / c, nll, self.epsilon)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## \u6a21\u578b\u8bad\u7ec3"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u8fd9\u91cc\u6a21\u578b\u9009\u62e9\u6bd4\u8f83\u77ed\u7684resnet50\u8dd1\u8d77\u6765\u6bd4\u8f83\u5feb\nmodel_ft = models.resnet50(pretrained=False)\n# \u8bad\u7ec3\u6743\u91cd\u6211\u81ea\u5df1\u4e0b\u8f7d\u7684\uff0c\u7136\u540e\u62f7\u8d1d\u5230\u4e86notebook\u76ee\u5f55\u4e0b\u9762\nmodel_ft.load_state_dict(torch.load('./resnet50-19c8e357.pth'))\nnum_ftrs = model_ft.fc.in_features\n# \u53ef\u4ee5\u5982\u4e0b\u5728\u5168\u8fde\u63a5\u5c42\u524d\u9762\u52a0\u5165dropout\u6765\u9632\u6b62\u8fc7\u62df\u5408\n# model_ft.fc = nn.Sequential(\n#     nn.Dropout(0.2),\n#     nn.Linear(2048, 10)\n# )\nmodel_ft.fc=nn.Linear(num_ftrs, 10)\nif use_gpu:\n    model_ft = model_ft.cuda()\n\n# define loss function\nlossfunc = nn.CrossEntropyLoss()\n# lossfunc = LabelSmoothingCrossEntropy()\n\n# \u8fd9\u91cc\u76f4\u63a5\u8bad\u7ec3\u6574\u4e2a\u7f51\u7edc\uff0c\u4e5f\u53ef\u4ee5\u50cf\u539f\u6765baseline\u5148fc\u540e\u89e3\u51bb\u6574\u4e2a\u7f51\u7edc\nparameters = list(model_ft.parameters())\noptimizer_ft = optim.SGD(parameters, lr=0.001, momentum=0.9, nesterov=True)\n\n# \u4f7f\u7528ReduceLROnPlateau\u5b66\u4e60\u8c03\u5ea6\u5668\uff0c\u5982\u679c\u4e09\u4e2aepoch\u51c6\u786e\u7387\u6ca1\u6709\u63d0\u5347\uff0c\u5219\u51cf\u5c11\u5b66\u4e60\u7387\nexp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft,mode='max',patience=3,verbose=True)\nmodel_ft,train_acc,valid_acc = train_model(model=model_ft,\n                           lossfunc=lossfunc,\n                           optimizer=optimizer_ft,\n                           scheduler=exp_lr_scheduler,\n                           num_epochs=20)", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Epoch 0/19\n----------\ntrain Loss: 0.0218 Acc: 0.6553\nval Loss: 0.0091 Acc: 0.8760\nEpoch 1/19\n----------\ntrain Loss: 0.0065 Acc: 0.8893\nval Loss: 0.0048 Acc: 0.9160\nEpoch 2/19\n----------\ntrain Loss: 0.0042 Acc: 0.9213\nval Loss: 0.0035 Acc: 0.9380\nEpoch 3/19\n----------\ntrain Loss: 0.0029 Acc: 0.9480\nval Loss: 0.0031 Acc: 0.9420\nEpoch 4/19\n----------\ntrain Loss: 0.0022 Acc: 0.9633\nval Loss: 0.0026 Acc: 0.9480\nEpoch 5/19\n----------\ntrain Loss: 0.0019 Acc: 0.9691\nval Loss: 0.0024 Acc: 0.9580\nEpoch 6/19\n----------\ntrain Loss: 0.0014 Acc: 0.9787\nval Loss: 0.0022 Acc: 0.9520\nEpoch 7/19\n----------\ntrain Loss: 0.0012 Acc: 0.9833\nval Loss: 0.0022 Acc: 0.9560\nEpoch 8/19\n----------\ntrain Loss: 0.0009 Acc: 0.9871\nval Loss: 0.0020 Acc: 0.9580\nEpoch 9/19\n----------\ntrain Loss: 0.0007 Acc: 0.9911\nval Loss: 0.0020 Acc: 0.9640\nEpoch 10/19\n----------\ntrain Loss: 0.0007 Acc: 0.9924\nval Loss: 0.0018 Acc: 0.9580\nEpoch 11/19\n----------\ntrain Loss: 0.0006 Acc: 0.9931\nval Loss: 0.0018 Acc: 0.9660\nEpoch 12/19\n----------\ntrain Loss: 0.0004 Acc: 0.9967\nval Loss: 0.0018 Acc: 0.9580\nEpoch 13/19\n----------\ntrain Loss: 0.0004 Acc: 0.9967\nval Loss: 0.0018 Acc: 0.9600\nEpoch 14/19\n----------\ntrain Loss: 0.0003 Acc: 0.9978\nval Loss: 0.0018 Acc: 0.9600\nEpoch 15/19\n----------\ntrain Loss: 0.0003 Acc: 0.9973\nval Loss: 0.0019 Acc: 0.9620\nEpoch    15: reducing learning rate of group 0 to 1.0000e-04.\nEpoch 16/19\n----------\ntrain Loss: 0.0003 Acc: 0.9971\nval Loss: 0.0019 Acc: 0.9540\nEpoch 17/19\n----------\ntrain Loss: 0.0003 Acc: 0.9960\nval Loss: 0.0019 Acc: 0.9560\nEpoch 18/19\n----------\ntrain Loss: 0.0003 Acc: 0.9958\nval Loss: 0.0019 Acc: 0.9540\nEpoch 19/19\n----------\ntrain Loss: 0.0002 Acc: 0.9984\nval Loss: 0.0018 Acc: 0.9600\nEpoch    19: reducing learning rate of group 0 to 1.0000e-05.\nTraining complete in 14m 20s\nBest val Acc: 0.966000\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# acc \u66f2\u7ebf\n# best = 9540\n%matplotlib inline\nimport matplotlib.pylab as plt\nplt.plot(train_acc,label=\"train\")\nplt.plot(valid_acc,label='valid')\nplt.legend()\nplt.plot()", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "INFO:matplotlib.font_manager:font search path ['/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf', '/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/afm', '/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\nINFO:matplotlib.font_manager:generated new fontManager\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "[]"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## \u4fdd\u5b58"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "torch.save(model_ft.state_dict(), './model.pth')", "execution_count": 19, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import moxing as mox\n# \u6ce8\u610f\u62f7\u8d1d\u5230\u81ea\u5df1\u7684\u76ee\u5f55\u73af\u5883\u4e0b\u9762\u5373\u53ef\nmox.file.copy('./model.pth','s3://ai-awe-n4/model_god/model/resnet-50.pth')\nprint(\"done\")", "execution_count": 20, "outputs": [{"output_type": "stream", "text": "done\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## \u63a8\u7406"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# \u4fee\u6539\u91cc\u9762\u7684\u7f51\u7edc\u5b9a\u4e49\u51fd\u6570resnet50\u5373\u53ef,\u63a5\u53e3\u901a\u5e38\u4fee\u6539\u4e3a\u548cval\u7684tansform\u4e00\u81f4\nmean,std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\ninfer_transformation = transforms.Compose([\n    transforms.Resize((224,224)),\n    # transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean,std)\n])\n\ndef resnet50(model_path, **kwargs):\n\n    \"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = models.resnet34(pretrained=False)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 10)\n    model.load_state_dict(torch.load(model_path,map_location ='cpu'))\n\n    model.eval()\n\n    return model", "execution_count": 21, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pytorch-1.0.0", "display_name": "Pytorch-1.0.0", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}